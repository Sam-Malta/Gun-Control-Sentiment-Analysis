{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test if a general purpose sentiment analysis model can be used to predict the sentiment of political tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from transformers import RobertaModel\n",
    "from transformers import RobertaTokenizer\n",
    "from roberta_classifer import RobertaClassifier\n",
    "    \n",
    "# Instantiate the model\n",
    "model = RobertaClassifier()\n",
    "\n",
    "# Load pre-trained weights\n",
    "#model.load_state_dict(torch.load('final_roberta_classifier.pt'))\n",
    "\n",
    "#model.to('cuda')\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def roberta_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to('cuda') for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate confidence\n",
    "    probs = F.softmax(all_logits, dim=1).cpu()\n",
    "\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_data = [\"I want more gun control\", \"I'm against gun control\"]\n",
    "test_inputs, test_masks = model.preprocess_for_roberta(test_data)\n",
    "\n",
    "# Create dataloader\n",
    "test_dataloader = model.create_dataloader(test_inputs, test_masks, batch_size)\n",
    "\n",
    "# Compute predicted probabilities on the test set\n",
    "probs = torch.argmax(roberta_predict(model, test_dataloader), dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {0: \"Negative\", 1: \"Positive\"}\n",
    "\n",
    "def create_prediction_dictionary(sentences, labels):\n",
    "    prediction_dict = {}\n",
    "    for i in range(len(sentences)):\n",
    "        prediction_dict[sentences[i]] = labels_map[labels[i].item()]\n",
    "    return prediction_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = create_prediction_dictionary(test_data, probs)\n",
    "sentiment_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facebook-scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d814e548a47325464e0881685482a82a9f7ebc33e0749d2240cc066ce05521f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
